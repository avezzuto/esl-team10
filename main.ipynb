{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:18:45.990729Z",
     "start_time": "2025-12-19T16:18:45.974558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from itertools import combinations"
   ],
   "id": "3f1d8e917fa49c2e",
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-19T15:55:48.554527Z",
     "start_time": "2025-12-19T15:55:48.221417Z"
    }
   },
   "source": [
    "# Download dataset from Kaggle\n",
    "path = kagglehub.dataset_download(\"nechbamohammed/research-papers-dataset\")\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/andreavezzuto/.cache/kagglehub/datasets/nechbamohammed/research-papers-dataset/versions/1\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:55:55.083046Z",
     "start_time": "2025-12-19T15:55:48.555847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read dataset into pandas dataframe\n",
    "df = pd.read_csv(os.path.join(path, 'dblp-v10.csv'))\n",
    "print(f\"Loaded dblp-v10.csv with shape {df.shape}\")"
   ],
   "id": "739593bf7202b683",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dblp-v10.csv with shape (1000000, 8)\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:56:00.730138Z",
     "start_time": "2025-12-19T15:55:55.128338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Some preprocessing... make the authors of a paper into a list\n",
    "df['authors'] = df['authors'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])"
   ],
   "id": "d28167abb90953d2",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:56:00.914222Z",
     "start_time": "2025-12-19T15:56:00.775964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We need to reduce the size of our data for graph-based analysis. We select papers between 2009 and 2010, which are about 100k\n",
    "START_YEAR = 2009\n",
    "END_YEAR = 2010\n",
    "df = df[(df['year'] >= START_YEAR) & (df['year'] <= END_YEAR)]\n",
    "print(f\"After temporal filtering: {df.shape[0]} papers\")"
   ],
   "id": "71bdc80015854e76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After temporal filtering: 104493 papers\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:56:00.997838Z",
     "start_time": "2025-12-19T15:56:00.914920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count papers per author\n",
    "author_paper_count = defaultdict(int)\n",
    "for authors in df['authors']:\n",
    "    for a in authors:\n",
    "        author_paper_count[a] += 1\n",
    "\n",
    "# Using the count we keep only authors with >=2 papers to reduce graph size further\n",
    "eligible_authors = {a for a, c in author_paper_count.items() if c >= 2}\n",
    "print(f\"Eligible authors (>=2 papers): {len(eligible_authors)}\")\n",
    "\n",
    "def filter_authors(authors):\n",
    "    return [a for a in authors if a in eligible_authors]\n",
    "\n",
    "df['authors'] = df['authors'].apply(filter_authors)\n",
    "\n",
    "# Remove papers with <1 eligible author\n",
    "df = df[df['authors'].map(len) > 0]\n",
    "print(f\"After filtering for eligible authors: {df.shape[0]} papers\")"
   ],
   "id": "3191e3a0c358e31b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible authors (>=2 papers): 60572\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:56:01.113803Z",
     "start_time": "2025-12-19T15:56:01.083936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We reduce the dataset further to 3000 randomly selected papers. Based on my testing, this is the max we can have before graph feature calculations explode in terms of time complexity\n",
    "TARGET_PAPERS = 3000\n",
    "if df.shape[0] > TARGET_PAPERS:\n",
    "    df = df.sample(n=TARGET_PAPERS, random_state=42).reset_index(drop=True)\n",
    "    print(f\"After random sampling: {df.shape[0]} papers\")"
   ],
   "id": "71dae111f90796ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After random sampling: 3000 papers\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:56:01.129295Z",
     "start_time": "2025-12-19T15:56:01.114400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Map storing the number of citations for a particular author\n",
    "author_total_citations = defaultdict(int)\n",
    "\n",
    "for authors, cites in zip(df['authors'], df['n_citation']):\n",
    "    for a in authors:\n",
    "        author_total_citations[a] += cites\n",
    "\n",
    "list(author_total_citations.items())[:10]"
   ],
   "id": "8aaad0ba34fc13a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Js Li', 50),\n",
       " ('Yang Shen', 0),\n",
       " ('Jakub T. MoÅ›cicki', 156),\n",
       " ('H. Lee', 156),\n",
       " ('Xuemei Chen', 1),\n",
       " ('Dimitrios Katsaros', 0),\n",
       " ('Xing Su', 50),\n",
       " ('Tiejun Huang', 50),\n",
       " ('Wen Gao', 65),\n",
       " ('Anju Verma', 50)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:56:01.142741Z",
     "start_time": "2025-12-19T15:56:01.129945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# 1. Add nodes with attributes\n",
    "for a in author_total_citations:\n",
    "    G.add_node(a, total_citations=author_total_citations[a])\n",
    "\n",
    "# 2. Add edges between nodes\n",
    "for authors in df['authors']:\n",
    "    # Add an edge for all pairs of coauthors for this paper\n",
    "    for a1, a2 in combinations(authors, 2):\n",
    "        if G.has_edge(a1, a2):\n",
    "            G[a1][a2]['weight'] += 1\n",
    "        else:\n",
    "            G.add_edge(a1, a2, weight=1)"
   ],
   "id": "44b6444f226ce5dc",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:56:01.168726Z",
     "start_time": "2025-12-19T15:56:01.146268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Authors (nodes):\", G.number_of_nodes())\n",
    "print(\"Coauthor edges:\", G.number_of_edges())"
   ],
   "id": "d3323c560337c747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors (nodes): 6547\n",
      "Coauthor edges: 7299\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:56:01.180842Z",
     "start_time": "2025-12-19T15:56:01.169105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prestige of an author in the coauthor network\n",
    "pagerank = nx.pagerank(G, weight='weight')"
   ],
   "id": "6775bdf4a3a94a4b",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:56:14.303633Z",
     "start_time": "2025-12-19T15:56:01.182407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How much an author bridges different groups\n",
    "betweenness = nx.betweenness_centrality(G)"
   ],
   "id": "1e3832c14e263921",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:59:51.333051Z",
     "start_time": "2025-12-19T16:59:51.305693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How central an author is to the network\n",
    "closeness = nx.closeness_centrality(G)"
   ],
   "id": "48792f8634f72f1e",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:47:48.616721Z",
     "start_time": "2025-12-19T16:47:47.661252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define top-K influential authors by PageRank\n",
    "top_k = 50\n",
    "top_authors = sorted(pagerank, key=pagerank.get, reverse=True)[:top_k]\n",
    "\n",
    "# dictionary mapping authors to min distance to any top 50 author\n",
    "min_distances = {}\n",
    "\n",
    "for a in G.nodes():\n",
    "    dists_to_top = [nx.shortest_path_length(G, source=a, target=t)\n",
    "                    for t in top_authors if nx.has_path(G, a, t)]\n",
    "    if dists_to_top:\n",
    "        min_distances[a] = min(dists_to_top)\n",
    "    else:\n",
    "        # Edge case: no top author is reachable (we might want to change this to a more reasonable number)\n",
    "        min_distances[a] = np.nan"
   ],
   "id": "ab2d7c3cb9f943db",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T16:52:28.501767Z",
     "start_time": "2025-12-19T16:52:28.491346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute mean citations per venue\n",
    "venue_mean_citations = df.groupby('venue')['n_citation'].mean().to_dict()\n",
    "\n",
    "# Compute total papers per venue\n",
    "venue_paper_count = df.groupby('venue').size().to_dict()"
   ],
   "id": "d23642a47735639c",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:43:42.807227Z",
     "start_time": "2025-12-19T17:43:42.198858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#==============================\n",
    "# GRAPH-BASED FEATURES PER AUTHOR\n",
    "#==============================\n",
    "\n",
    "# Node-level features dictionary\n",
    "author_features = {}\n",
    "for a in G.nodes():\n",
    "    author_features[a] = {\n",
    "        'pagerank': pagerank[a],\n",
    "        'betweenness': betweenness[a],\n",
    "        'closeness': closeness[a],\n",
    "        'min_distance_to_top_author': min_distances[a],\n",
    "        'weighted_degree': sum(d['weight'] for _, _, d in G.edges(a, data=True)),\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# author_features['Some Author']['pagerank'] gives PageRank\n",
    "# author_features['Some Author']['degree'] gives number of coauthors\n",
    "\n",
    "#==============================\n",
    "# PAPER-LEVEL GRAPH FEATURES\n",
    "#==============================\n",
    "# Aggregate author-level features per paper\n",
    "def paper_graph_features(authors):\n",
    "    known_authors = [a for a in authors if a in author_features]\n",
    "\n",
    "    # aggregate stats per paper\n",
    "    pr = np.array([author_features[a]['pagerank'] for a in known_authors])\n",
    "    bt = np.array([author_features[a]['betweenness'] for a in known_authors])\n",
    "    cl = np.array([author_features[a]['closeness'] for a in known_authors])\n",
    "    md = np.array([author_features[a]['min_distance_to_top_author'] for a in known_authors])\n",
    "    wdeg = np.array([author_features[a]['weighted_degree'] for a in known_authors])\n",
    "\n",
    "    return {\n",
    "        'mean_pagerank': pr.mean() if len(pr) > 0 else 0,\n",
    "        'max_pagerank': pr.max() if len(pr) > 0 else 0,\n",
    "        'std_pagerank': pr.std() if len(pr) > 0 else 0,\n",
    "        'mean_betweenness': bt.mean() if len(bt) > 0 else 0,\n",
    "        'max_betweenness': bt.max() if len(bt) > 0 else 0,\n",
    "        'mean_closeness': cl.mean() if len(cl) > 0 else 0,\n",
    "        'max_closeness': cl.max() if len(cl) > 0 else 0,\n",
    "        'mean_min_distance_to_top_author': md.mean() if len(md) > 0 else 0,\n",
    "        'max_min_distance_to_top_author': md.max() if len(md) > 0 else 0,\n",
    "        'mean_weighted_degree': wdeg.mean() if len(wdeg) > 0 else 0,\n",
    "        'max_weighted_degree': wdeg.max() if len(wdeg) > 0 else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "# Apply to all papers\n",
    "graph_features_df = df['authors'].apply(paper_graph_features).apply(pd.Series)\n",
    "graph_features_df.head()\n",
    "\n",
    "# Example:\n",
    "# graph_features_df.iloc[0]['mean_pagerank'] gives average prestige of first paper's authors"
   ],
   "id": "f613f08f9028f002",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph features shape: (3000, 11)\n",
      "Non-graph features shape: (3000, 7)\n",
      "Combined features shape: (3000, 20)\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#==============================\n",
    "# NON-GRAPH FEATURES PER PAPER\n",
    "#==============================\n",
    "# - num_papers: how many papers an author has published\n",
    "# - total_citations: total citations of an author\n",
    "# - citations_per_paper: average citations per paper\n",
    "# - venue: statistics on a particular venue (mean citations per paper at the venue, total number of papers at the venue)\n",
    "author_papers_count = defaultdict(int)\n",
    "author_citations_total = defaultdict(int)\n",
    "for authors, cites in zip(df['authors'], df['n_citation']):\n",
    "    for a in authors:\n",
    "        author_papers_count[a] += 1\n",
    "        author_citations_total[a] += cites\n",
    "\n",
    "# Paper-level aggregation\n",
    "def paper_non_graph_features(authors, venue):\n",
    "    counts = [author_papers_count.get(a, 0) for a in authors]\n",
    "    citations = [author_citations_total.get(a, 0) for a in authors]\n",
    "    mean_cites_venue = venue_mean_citations.get(venue, np.nan)\n",
    "    num_papers_venue = venue_paper_count.get(venue, 0)\n",
    "\n",
    "    return {\n",
    "        'mean_num_papers': np.mean(counts) if counts else 0,\n",
    "        'max_num_papers': np.max(counts) if counts else 0,\n",
    "        'mean_total_citations': np.mean(citations) if citations else 0,\n",
    "        'max_total_citations': np.max(citations) if citations else 0,\n",
    "        'sum_total_citations': np.sum(citations) if citations else 0,\n",
    "        'venue_mean_citations': mean_cites_venue,\n",
    "        'venue_num_papers': num_papers_venue\n",
    "    }\n",
    "\n",
    "non_graph_features_df = df.apply(\n",
    "    lambda row: paper_non_graph_features(row['authors'], row['venue']), axis=1\n",
    ").apply(pd.Series)\n",
    "non_graph_features_df.head()\n",
    "\n",
    "# Example:\n",
    "# non_graph_features_df.iloc[0]['mean_num_papers'] is average productivity of authors of first paper"
   ],
   "id": "3ebdbe3739702b1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Combined features and ground truths ready for model input\n",
    "X_graph = graph_features_df\n",
    "X_non_graph = non_graph_features_df\n",
    "X_all = pd.concat([graph_features_df, non_graph_features_df, df_meta], axis=1)\n",
    "y = df['n_citation']\n",
    "\n",
    "print(\"Graph features shape:\", X_graph.shape)\n",
    "print(\"Non-graph features shape:\", X_non_graph.shape)\n",
    "print(\"Combined features shape:\", X_all.shape)"
   ],
   "id": "776981edcbf814a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
