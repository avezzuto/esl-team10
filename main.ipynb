{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:06.554059Z",
     "start_time": "2025-12-19T17:46:06.534647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from itertools import combinations"
   ],
   "id": "3f1d8e917fa49c2e",
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:06.992769Z",
     "start_time": "2025-12-19T17:46:06.569187Z"
    }
   },
   "source": [
    "# Download dataset from Kaggle\n",
    "path = kagglehub.dataset_download(\"nechbamohammed/research-papers-dataset\")\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/andreavezzuto/.cache/kagglehub/datasets/nechbamohammed/research-papers-dataset/versions/1\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:13.671503Z",
     "start_time": "2025-12-19T17:46:06.994946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read dataset into pandas dataframe\n",
    "df = pd.read_csv(os.path.join(path, 'dblp-v10.csv'))\n",
    "print(f\"Loaded dblp-v10.csv with shape {df.shape}\")"
   ],
   "id": "739593bf7202b683",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dblp-v10.csv with shape (1000000, 8)\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:19.239944Z",
     "start_time": "2025-12-19T17:46:13.730573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Some preprocessing... make the authors of a paper into a list\n",
    "df['authors'] = df['authors'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])"
   ],
   "id": "d28167abb90953d2",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:19.435712Z",
     "start_time": "2025-12-19T17:46:19.299347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We need to reduce the size of our data for graph-based analysis. We select papers between 2009 and 2010, which are about 100k\n",
    "START_YEAR = 2009\n",
    "END_YEAR = 2010\n",
    "df = df[(df['year'] >= START_YEAR) & (df['year'] <= END_YEAR)]\n",
    "print(f\"After temporal filtering: {df.shape[0]} papers\")"
   ],
   "id": "71bdc80015854e76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After temporal filtering: 104493 papers\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:19.585167Z",
     "start_time": "2025-12-19T17:46:19.436831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count papers per author\n",
    "author_paper_count = defaultdict(int)\n",
    "for authors in df['authors']:\n",
    "    for a in authors:\n",
    "        author_paper_count[a] += 1\n",
    "\n",
    "# Using the count we keep only authors with >=2 papers to reduce graph size further\n",
    "eligible_authors = {a for a, c in author_paper_count.items() if c >= 2}\n",
    "print(f\"Eligible authors (>=2 papers): {len(eligible_authors)}\")\n",
    "\n",
    "def filter_authors(authors):\n",
    "    return [a for a in authors if a in eligible_authors]\n",
    "\n",
    "df['authors'] = df['authors'].apply(filter_authors)\n",
    "\n",
    "# Remove papers with <1 eligible author\n",
    "df = df[df['authors'].map(len) > 0]\n",
    "print(f\"After filtering for eligible authors: {df.shape[0]} papers\")"
   ],
   "id": "3191e3a0c358e31b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible authors (>=2 papers): 60572\n",
      "After filtering for eligible authors: 88880 papers\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:19.622508Z",
     "start_time": "2025-12-19T17:46:19.585699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We reduce the dataset further to 3000 randomly selected papers. Based on my testing, this is the max we can have before graph feature calculations explode in terms of time complexity\n",
    "TARGET_PAPERS = 3000\n",
    "if df.shape[0] > TARGET_PAPERS:\n",
    "    df = df.sample(n=TARGET_PAPERS, random_state=42).reset_index(drop=True)\n",
    "    print(f\"After random sampling: {df.shape[0]} papers\")"
   ],
   "id": "71dae111f90796ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After random sampling: 3000 papers\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:19.647963Z",
     "start_time": "2025-12-19T17:46:19.623182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Map storing the number of citations for a particular author\n",
    "author_total_citations = defaultdict(int)\n",
    "\n",
    "for authors, cites in zip(df['authors'], df['n_citation']):\n",
    "    for a in authors:\n",
    "        author_total_citations[a] += cites\n",
    "\n",
    "list(author_total_citations.items())[:10]"
   ],
   "id": "8aaad0ba34fc13a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Js Li', 50),\n",
       " ('Yang Shen', 0),\n",
       " ('Jakub T. MoÅ›cicki', 156),\n",
       " ('H. Lee', 156),\n",
       " ('Xuemei Chen', 1),\n",
       " ('Dimitrios Katsaros', 0),\n",
       " ('Xing Su', 50),\n",
       " ('Tiejun Huang', 50),\n",
       " ('Wen Gao', 65),\n",
       " ('Anju Verma', 50)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:19.662365Z",
     "start_time": "2025-12-19T17:46:19.649396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# 1. Add nodes with attributes\n",
    "for a in author_total_citations:\n",
    "    G.add_node(a, total_citations=author_total_citations[a])\n",
    "\n",
    "# 2. Add edges between nodes\n",
    "for authors in df['authors']:\n",
    "    # Add an edge for all pairs of coauthors for this paper\n",
    "    for a1, a2 in combinations(authors, 2):\n",
    "        if G.has_edge(a1, a2):\n",
    "            G[a1][a2]['weight'] += 1\n",
    "        else:\n",
    "            G.add_edge(a1, a2, weight=1)"
   ],
   "id": "44b6444f226ce5dc",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:19.676832Z",
     "start_time": "2025-12-19T17:46:19.662750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Authors (nodes):\", G.number_of_nodes())\n",
    "print(\"Coauthor edges:\", G.number_of_edges())"
   ],
   "id": "d3323c560337c747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors (nodes): 6547\n",
      "Coauthor edges: 7299\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:19.691477Z",
     "start_time": "2025-12-19T17:46:19.677754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prestige of an author in the coauthor network\n",
    "pagerank = nx.pagerank(G, weight='weight')"
   ],
   "id": "6775bdf4a3a94a4b",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:42.539268Z",
     "start_time": "2025-12-19T17:46:19.691999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How much an author bridges different groups\n",
    "betweenness = nx.betweenness_centrality(G)"
   ],
   "id": "1e3832c14e263921",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:42.614899Z",
     "start_time": "2025-12-19T17:46:42.598727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How central an author is to the network\n",
    "closeness = nx.closeness_centrality(G)"
   ],
   "id": "48792f8634f72f1e",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:43.654253Z",
     "start_time": "2025-12-19T17:46:42.616386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define top-K influential authors by PageRank\n",
    "top_k = 50\n",
    "top_authors = sorted(pagerank, key=pagerank.get, reverse=True)[:top_k]\n",
    "\n",
    "# dictionary mapping authors to min distance to any top 50 author\n",
    "min_distances = {}\n",
    "\n",
    "for a in G.nodes():\n",
    "    dists_to_top = [nx.shortest_path_length(G, source=a, target=t)\n",
    "                    for t in top_authors if nx.has_path(G, a, t)]\n",
    "    if dists_to_top:\n",
    "        min_distances[a] = min(dists_to_top)\n",
    "    else:\n",
    "        # Edge case: no top author is reachable (we might want to change this to a more reasonable number)\n",
    "        min_distances[a] = np.nan"
   ],
   "id": "ab2d7c3cb9f943db",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:43.736965Z",
     "start_time": "2025-12-19T17:46:43.729412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute mean citations per venue\n",
    "venue_mean_citations = df.groupby('venue')['n_citation'].mean().to_dict()\n",
    "\n",
    "# Compute total papers per venue\n",
    "venue_paper_count = df.groupby('venue').size().to_dict()"
   ],
   "id": "d23642a47735639c",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:43.935272Z",
     "start_time": "2025-12-19T17:46:43.737332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#==============================\n",
    "# GRAPH-BASED FEATURES PER AUTHOR\n",
    "#==============================\n",
    "\n",
    "# Node-level features dictionary\n",
    "author_features = {}\n",
    "for a in G.nodes():\n",
    "    author_features[a] = {\n",
    "        'pagerank': pagerank[a],\n",
    "        'betweenness': betweenness[a],\n",
    "        'closeness': closeness[a],\n",
    "        'min_distance_to_top_author': min_distances[a],\n",
    "        'weighted_degree': sum(d['weight'] for _, _, d in G.edges(a, data=True)),\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# author_features['Some Author']['pagerank'] gives PageRank\n",
    "# author_features['Some Author']['degree'] gives number of coauthors\n",
    "\n",
    "#==============================\n",
    "# PAPER-LEVEL GRAPH FEATURES\n",
    "#==============================\n",
    "# Aggregate author-level features per paper\n",
    "def paper_graph_features(authors):\n",
    "    known_authors = [a for a in authors if a in author_features]\n",
    "\n",
    "    # aggregate stats per paper\n",
    "    pr = np.array([author_features[a]['pagerank'] for a in known_authors])\n",
    "    bt = np.array([author_features[a]['betweenness'] for a in known_authors])\n",
    "    cl = np.array([author_features[a]['closeness'] for a in known_authors])\n",
    "    md = np.array([author_features[a]['min_distance_to_top_author'] for a in known_authors])\n",
    "    wdeg = np.array([author_features[a]['weighted_degree'] for a in known_authors])\n",
    "\n",
    "    return {\n",
    "        'mean_pagerank': pr.mean() if len(pr) > 0 else 0,\n",
    "        'max_pagerank': pr.max() if len(pr) > 0 else 0,\n",
    "        'std_pagerank': pr.std() if len(pr) > 0 else 0,\n",
    "        'mean_betweenness': bt.mean() if len(bt) > 0 else 0,\n",
    "        'max_betweenness': bt.max() if len(bt) > 0 else 0,\n",
    "        'mean_closeness': cl.mean() if len(cl) > 0 else 0,\n",
    "        'max_closeness': cl.max() if len(cl) > 0 else 0,\n",
    "        'mean_min_distance_to_top_author': md.mean() if len(md) > 0 else 0,\n",
    "        'max_min_distance_to_top_author': md.max() if len(md) > 0 else 0,\n",
    "        'mean_weighted_degree': wdeg.mean() if len(wdeg) > 0 else 0,\n",
    "        'max_weighted_degree': wdeg.max() if len(wdeg) > 0 else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "# Apply to all papers\n",
    "graph_features_df = df['authors'].apply(paper_graph_features).apply(pd.Series)\n",
    "graph_features_df.head()\n",
    "\n",
    "# Example:\n",
    "# graph_features_df.iloc[0]['mean_pagerank'] gives average prestige of first paper's authors"
   ],
   "id": "f613f08f9028f002",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mean_pagerank  max_pagerank  std_pagerank  mean_betweenness  \\\n",
       "0       0.000026      0.000026           0.0               0.0   \n",
       "1       0.000026      0.000026           0.0               0.0   \n",
       "2       0.000171      0.000171           0.0               0.0   \n",
       "3       0.000026      0.000026           0.0               0.0   \n",
       "4       0.000026      0.000026           0.0               0.0   \n",
       "\n",
       "   max_betweenness  mean_closeness  max_closeness  \\\n",
       "0              0.0        0.000000       0.000000   \n",
       "1              0.0        0.000000       0.000000   \n",
       "2              0.0        0.000153       0.000153   \n",
       "3              0.0        0.000000       0.000000   \n",
       "4              0.0        0.000000       0.000000   \n",
       "\n",
       "   mean_min_distance_to_top_author  max_min_distance_to_top_author  \\\n",
       "0                              NaN                             NaN   \n",
       "1                              NaN                             NaN   \n",
       "2                              NaN                             NaN   \n",
       "3                              NaN                             NaN   \n",
       "4                              NaN                             NaN   \n",
       "\n",
       "   mean_weighted_degree  max_weighted_degree  \n",
       "0                   0.0                  0.0  \n",
       "1                   0.0                  0.0  \n",
       "2                   1.0                  1.0  \n",
       "3                   0.0                  0.0  \n",
       "4                   0.0                  0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_pagerank</th>\n",
       "      <th>max_pagerank</th>\n",
       "      <th>std_pagerank</th>\n",
       "      <th>mean_betweenness</th>\n",
       "      <th>max_betweenness</th>\n",
       "      <th>mean_closeness</th>\n",
       "      <th>max_closeness</th>\n",
       "      <th>mean_min_distance_to_top_author</th>\n",
       "      <th>max_min_distance_to_top_author</th>\n",
       "      <th>mean_weighted_degree</th>\n",
       "      <th>max_weighted_degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:44.093656Z",
     "start_time": "2025-12-19T17:46:43.936788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#==============================\n",
    "# NON-GRAPH FEATURES PER PAPER\n",
    "#==============================\n",
    "# - num_papers: how many papers an author has published\n",
    "# - total_citations: total citations of an author\n",
    "# - citations_per_paper: average citations per paper\n",
    "# - venue: statistics on a particular venue (mean citations per paper at the venue, total number of papers at the venue)\n",
    "author_papers_count = defaultdict(int)\n",
    "author_citations_total = defaultdict(int)\n",
    "for authors, cites in zip(df['authors'], df['n_citation']):\n",
    "    for a in authors:\n",
    "        author_papers_count[a] += 1\n",
    "        author_citations_total[a] += cites\n",
    "\n",
    "# Paper-level aggregation\n",
    "def paper_non_graph_features(authors, venue):\n",
    "    counts = [author_papers_count.get(a, 0) for a in authors]\n",
    "    citations = [author_citations_total.get(a, 0) for a in authors]\n",
    "    mean_cites_venue = venue_mean_citations.get(venue, np.nan)\n",
    "    num_papers_venue = venue_paper_count.get(venue, 0)\n",
    "\n",
    "    return {\n",
    "        'mean_num_papers': np.mean(counts) if counts else 0,\n",
    "        'max_num_papers': np.max(counts) if counts else 0,\n",
    "        'mean_total_citations': np.mean(citations) if citations else 0,\n",
    "        'max_total_citations': np.max(citations) if citations else 0,\n",
    "        'sum_total_citations': np.sum(citations) if citations else 0,\n",
    "        'venue_mean_citations': mean_cites_venue,\n",
    "        'venue_num_papers': num_papers_venue\n",
    "    }\n",
    "\n",
    "non_graph_features_df = df.apply(\n",
    "    lambda row: paper_non_graph_features(row['authors'], row['venue']), axis=1\n",
    ").apply(pd.Series)\n",
    "non_graph_features_df.head()\n",
    "\n",
    "# Example:\n",
    "# non_graph_features_df.iloc[0]['mean_num_papers'] is average productivity of authors of first paper"
   ],
   "id": "3ebdbe3739702b1c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mean_num_papers  max_num_papers  mean_total_citations  max_total_citations  \\\n",
       "0              1.0             1.0                  50.0                 50.0   \n",
       "1              1.0             1.0                   0.0                  0.0   \n",
       "2              1.0             1.0                 156.0                156.0   \n",
       "3              1.0             1.0                   1.0                  1.0   \n",
       "4              1.0             1.0                   0.0                  0.0   \n",
       "\n",
       "   sum_total_citations  venue_mean_citations  venue_num_papers  \n",
       "0                 50.0                  79.5               4.0  \n",
       "1                  0.0                   NaN               0.0  \n",
       "2                312.0                 103.0               2.0  \n",
       "3                  1.0                   NaN               0.0  \n",
       "4                  0.0                   5.0               2.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_num_papers</th>\n",
       "      <th>max_num_papers</th>\n",
       "      <th>mean_total_citations</th>\n",
       "      <th>max_total_citations</th>\n",
       "      <th>sum_total_citations</th>\n",
       "      <th>venue_mean_citations</th>\n",
       "      <th>venue_num_papers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>79.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:46:44.485473Z",
     "start_time": "2025-12-19T17:46:44.251815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combined features and ground truths ready to be inputted\n",
    "X_graph = graph_features_df\n",
    "X_non_graph = non_graph_features_df\n",
    "X_all = pd.concat([graph_features_df, non_graph_features_df, df_meta], axis=1)\n",
    "y = df['n_citation']\n",
    "\n",
    "print(\"Graph features shape:\", X_graph.shape)\n",
    "print(\"Non-graph features shape:\", X_non_graph.shape)\n",
    "print(\"Combined features shape:\", X_all.shape)"
   ],
   "id": "776981edcbf814a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph features shape: (3000, 11)\n",
      "Non-graph features shape: (3000, 7)\n",
      "Combined features shape: (3000, 20)\n"
     ]
    }
   ],
   "execution_count": 122
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
